{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jxAXG53YyBU",
        "outputId": "681d3076-9c0b-4202-c526-d2ca0f9ec56f"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install pandas\n",
        "!pip3 install sklearn\n",
        "!pip3 install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-Bk2kszZcXf",
        "outputId": "5b77e1c4-3eb5-4179-91e7-bf8555dab597"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaXvqhD5WU5S",
        "outputId": "6216f661-c01e-44f9-808b-5913c6e4e8d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([56000, 784])\n",
            "torch.Size([14000, 784])\n",
            "torch.Size([56000])\n",
            "torch.Size([14000])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "mnist = fetch_openml('mnist_784')\n",
        "mnist.data.shape, mnist.target.shape\n",
        "x_data = mnist.data\n",
        "y_data = mnist.target.astype(int)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = 'cpu'\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.20, random_state=42)\n",
        "X_train, X_test = torch.Tensor(X_train.values), torch.Tensor(X_test.values)\n",
        "y_train, y_test = torch.Tensor(y_train.values), torch.Tensor(y_test.values)\n",
        "X_train = X_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EvBwFJGn2WTI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zMbVGeVN3PXR"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "epochs=2000\n",
        "model = MLP().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwxomyCxdTv2",
        "outputId": "e61282ea-6b8d-47f8-9f44-34fe7708e0b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====\n",
            "epoch  0\n",
            "loss  tensor(2.4096)\n",
            "train_accuracy 0.090\n",
            "test_accuracy 0.091\n",
            "====\n",
            "epoch  100\n",
            "loss  tensor(1.6791)\n",
            "train_accuracy 0.613\n",
            "test_accuracy 0.620\n",
            "====\n",
            "epoch  200\n",
            "loss  tensor(1.2827)\n",
            "train_accuracy 0.753\n",
            "test_accuracy 0.753\n",
            "====\n",
            "epoch  300\n",
            "loss  tensor(1.0483)\n",
            "train_accuracy 0.807\n",
            "test_accuracy 0.810\n",
            "====\n",
            "epoch  400\n",
            "loss  tensor(0.8946)\n",
            "train_accuracy 0.837\n",
            "test_accuracy 0.840\n",
            "====\n",
            "epoch  500\n",
            "loss  tensor(0.7865)\n",
            "train_accuracy 0.857\n",
            "test_accuracy 0.857\n",
            "====\n",
            "epoch  600\n",
            "loss  tensor(0.7065)\n",
            "train_accuracy 0.868\n",
            "test_accuracy 0.868\n",
            "====\n",
            "epoch  700\n",
            "loss  tensor(0.6450)\n",
            "train_accuracy 0.877\n",
            "test_accuracy 0.877\n",
            "====\n",
            "epoch  800\n",
            "loss  tensor(0.5962)\n",
            "train_accuracy 0.883\n",
            "test_accuracy 0.883\n",
            "====\n",
            "epoch  900\n",
            "loss  tensor(0.5565)\n",
            "train_accuracy 0.888\n",
            "test_accuracy 0.888\n",
            "====\n",
            "epoch  1000\n",
            "loss  tensor(0.5235)\n",
            "train_accuracy 0.892\n",
            "test_accuracy 0.892\n",
            "====\n",
            "epoch  1100\n",
            "loss  tensor(0.4956)\n",
            "train_accuracy 0.896\n",
            "test_accuracy 0.895\n",
            "====\n",
            "epoch  1200\n",
            "loss  tensor(0.4717)\n",
            "train_accuracy 0.899\n",
            "test_accuracy 0.898\n",
            "====\n",
            "epoch  1300\n",
            "loss  tensor(0.4509)\n",
            "train_accuracy 0.902\n",
            "test_accuracy 0.901\n",
            "====\n",
            "epoch  1400\n",
            "loss  tensor(0.4327)\n",
            "train_accuracy 0.904\n",
            "test_accuracy 0.902\n",
            "====\n",
            "epoch  1500\n",
            "loss  tensor(0.4165)\n",
            "train_accuracy 0.907\n",
            "test_accuracy 0.904\n",
            "====\n",
            "epoch  1600\n",
            "loss  tensor(0.4020)\n",
            "train_accuracy 0.909\n",
            "test_accuracy 0.905\n",
            "====\n",
            "epoch  1700\n",
            "loss  tensor(0.3890)\n",
            "train_accuracy 0.911\n",
            "test_accuracy 0.908\n",
            "====\n",
            "epoch  1800\n",
            "loss  tensor(0.3772)\n",
            "train_accuracy 0.913\n",
            "test_accuracy 0.909\n",
            "====\n",
            "epoch  1900\n",
            "loss  tensor(0.3665)\n",
            "train_accuracy 0.914\n",
            "test_accuracy 0.911\n"
          ]
        }
      ],
      "source": [
        "loss_save_arr=[]\n",
        "for i in range(epochs):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  output = model(X_train)\n",
        "  loss = criterion(output, y_train.long())\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  loss_save_arr.append(loss.data)\n",
        "  if(i%100==0):\n",
        "    print(\"====\")\n",
        "    print(\"epoch \", i)\n",
        "    print('loss ', loss.data)\n",
        "    _, pred = torch.max(output.data, axis=1)\n",
        "    print(\"train_accuracy {:0.3f}\".format(float((pred == y_train).sum())/y_train.size(0)))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      output = model(X_test)\n",
        "      _, pred = torch.max(output.data, axis=1)\n",
        "      print(\"test_accuracy {:0.3f}\".format(float((pred == y_test).sum())/y_test.size(0)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5feJR2DbbUN"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "  def forward(self, x):\n",
        "    outputs = torch.sigmoid(self.linear(x))\n",
        "    return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6RzGXiqWmSS",
        "outputId": "d2384e61-9cac-43d4-caa6-6005d97c8998"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "m = nn.Linear(20, 30)\n",
        "input = torch.randn(128, 20)\n",
        "output = m(input)\n",
        "print(output.shape)\n",
        "print(m.weight.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sP5N_1Ccct9U"
      },
      "outputs": [],
      "source": [
        "epochs = 1000\n",
        "input_dim =784\n",
        "output_dim = 10\n",
        "lr = 0.01\n",
        "model = LogisticRegression(input_dim, output_dim)\n",
        "model = model.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr =lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9acDn6rQda2_",
        "outputId": "4d7164a1-9f73-401a-f603-b675ed17aa3d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(range(epochs), [e.to(\"cpu\") for e in loss_save_arr])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled0.ipynb의 사본의 사본",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
